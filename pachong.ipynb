{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c448b0-f513-4cef-bd4d-e782c78c69a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取第 9800 页: http://job.mohrss.gov.cn/cjobs/jobinfolist/listJobinfolist?pageNo=9800\n",
      "已保存 2000 条数据到 job_information_part_1_20250407_224102.csv\n",
      "已完成 2000 条数据爬取\n",
      "正在爬取第 9900 页: http://job.mohrss.gov.cn/cjobs/jobinfolist/listJobinfolist?pageNo=9900\n",
      "已保存 2000 条数据到 job_information_part_2_20250407_230728.csv\n",
      "已完成 4000 条数据爬取\n",
      "正在爬取第 10000 页: http://job.mohrss.gov.cn/cjobs/jobinfolist/listJobinfolist?pageNo=10000\n",
      "已保存 1939 条数据到 job_information_final_part_20250407_233334.csv\n",
      "已合并所有数据，总计 199939 条记录\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2025.04.05\n",
    "# @Author  : Lin\n",
    "# @FileName: pachong.py\n",
    "\n",
    "'''\n",
    "使用selenium是为了自动控制浏览器进行操作，模拟人的操作，适用于那些通过传统手段（如 requests、BeautifulSoup）难以抓取的网站。\n",
    "由于 JavaScript 动态加载内容，传统爬虫请求后拿到的只是“骨架”，数据还没渲染，使用传统的工具没法获取信息，因此使用selenium\n",
    "'''\n",
    "\n",
    "# 设置 webdriver_manager 缓存路径为当前目录下的 drivers 文件夹\n",
    "#目的是为了不每次都重新下载WebDriver，设置缓存路径在项目根目录下的 drivers/。\n",
    "current_dir = os.getcwd()\n",
    "cache_path = os.path.join(current_dir, \"drivers\")\n",
    "\n",
    "# 确保目录存在\n",
    "if not os.path.exists(cache_path):\n",
    "    os.makedirs(cache_path)\n",
    "\n",
    "# 设置环境变量,确保 webdriver_manager 使用本地缓存\n",
    "os.environ['WDM_LOCAL'] = '1'\n",
    "os.environ['WDM_CACHE_PATH'] = cache_path\n",
    "\n",
    "# 配置 Selenium 使用 Edge\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(\"--headless\")  # 无界面模式\n",
    "edge_options.add_argument(\"--disable-gpu\")\n",
    "edge_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# 使用更新后的缓存路径安装 Edge WebDriver,使用 EdgeChromiumDriverManager().install() 自动下载适配版本。\n",
    "service = Service(EdgeChromiumDriverManager().install())\n",
    "driver = webdriver.Edge(service=service, options=edge_options)\n",
    "\n",
    "# 目标 URL（第一页）\n",
    "base_url = \"http://job.mohrss.gov.cn/cjobs/jobinfolist/listJobinfolist?pageNo=\"\n",
    "\n",
    "# 最大页数\n",
    "max_pages = 10000\n",
    "data = []\n",
    "record_count = 0  # 用于计数已爬取的记录数\n",
    "\n",
    "# 创建保存文件的函数\n",
    "def save_data(data_list, filename_prefix=\"job_data\"):\n",
    "    if not data_list:\n",
    "        print(\"没有数据需要保存\")\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") #用于文件名,防止重新运行文件名重复导致文件被覆盖\n",
    "    filename = f\"{filename_prefix}_{timestamp}.csv\"\n",
    "    \n",
    "    df = pd.DataFrame(data_list, columns=[\n",
    "        \"岗位名称\", \"月薪\", \"地区\", \"招聘单位\", \"学历要求\", \"提供住宿\", \"发布机构\", \n",
    "        \"工作性质\", \"工作地点\", \"岗位描述\", \"单位简介\", \"联系人\", \"联系电话\", \"电子邮箱\"\n",
    "    ])\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"已保存 {len(data_list)} 条数据到 {filename}\")\n",
    "\n",
    "# 爬取多页\n",
    "for page in range(9701, max_pages + 1):\n",
    "    url = f\"{base_url}{page}\"\n",
    "    if page%100==0:\n",
    "        print(f\"正在爬取第 {page} 页: {url}\")\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)  #尝试获取网页\n",
    "        time.sleep(0.1)  # 减少等待时间到0.1秒\n",
    "        \n",
    "        # 获取所有岗位的链接和基本信息，存储起来再处理\n",
    "        jobs_data = []\n",
    "        job_blocks = driver.find_elements(By.CLASS_NAME, \"list_show\")\n",
    "        \n",
    "        for job in job_blocks:\n",
    "            try:\n",
    "                # 获取岗位名称\n",
    "                job_name_element = job.find_element(By.CLASS_NAME, \"list_con_tit\").find_element(By.TAG_NAME, \"a\")\n",
    "                job_name = job_name_element.text.strip()\n",
    "                \n",
    "                # 获取详情页链接\n",
    "                job_link = job_name_element.get_attribute(\"href\")\n",
    "                \n",
    "                # 获取薪资 & 地区\n",
    "                salary = job.find_element(By.CLASS_NAME, \"jobs_pay\").text.strip()\n",
    "                location = job.find_element(By.CLASS_NAME, \"josbs_usetime\").text.strip()\n",
    "                \n",
    "                # 存储基本信息和链接\n",
    "                jobs_data.append({\n",
    "                    \"job_name\": job_name,\n",
    "                    \"job_link\": job_link,\n",
    "                    \"salary\": salary,\n",
    "                    \"location\": location\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                # print(f\"获取岗位基本信息失败: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 处理完当前页所有基本信息后，再逐个访问详情页\n",
    "        for job_info in jobs_data:\n",
    "            try:\n",
    "                # 访问详情页\n",
    "                driver.get(job_info[\"job_link\"])\n",
    "                \n",
    "                # 等待页面加载,加载时间设置1秒\n",
    "                WebDriverWait(driver, 1).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"job_name\"))\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    # 获取详情页中的实际薪资（更准确）\n",
    "                    actual_salary = \"-\"  #设置为-,防止未获取成功导致错误\n",
    "                    try:\n",
    "                        actual_salary = driver.find_element(By.CLASS_NAME, \"money\").text.strip()\n",
    "                    except:\n",
    "                        actual_salary = job_info[\"salary\"]  # 如果获取失败，使用列表页的薪资\n",
    "\n",
    "                    # 获取招聘单位\n",
    "                    company = \"-\"\n",
    "                    try:\n",
    "                        company_element = driver.find_element(By.XPATH, '//div[@class=\"job_name_bottom\"]/span[1]/span[2]/a')\n",
    "                        company = company_element.text.strip()\n",
    "                    except:\n",
    "                        try:\n",
    "                            company = driver.find_element(By.XPATH, '//div[@class=\"job_name_bottom\"]/span[1]/span[2]').text.strip()\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    # 获取学历要求\n",
    "                    education = \"-\"\n",
    "                    try:\n",
    "                        education = driver.find_element(By.XPATH, '//span[contains(text(), \"学历要求\")]/following-sibling::span').text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 获取提供住宿情况\n",
    "                    housing = \"-\"\n",
    "                    try:\n",
    "                        housing = driver.find_element(By.XPATH, '//span[contains(text(), \"提供住宿\")]/following-sibling::span').text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 获取发布机构\n",
    "                    publisher = \"-\"\n",
    "                    try:\n",
    "                        # 使用包含文本的XPath来找到正确的元素\n",
    "                        publisher_spans = driver.find_elements(By.XPATH, '//span[contains(text(), \"发布机构\")]')\n",
    "                        for span in publisher_spans:\n",
    "                            # 获取父元素的文本，去除\"发布机构：\"部分\n",
    "                            parent_span = span.find_element(By.XPATH, './..')\n",
    "                            publisher_text = parent_span.text.strip()\n",
    "                            if \"发布机构：\" in publisher_text:\n",
    "                                publisher = publisher_text.replace(\"发布机构：\", \"\").strip()\n",
    "                                break\n",
    "                    except Exception as e:\n",
    "                        # print(f\"获取发布机构失败: {e}\")\n",
    "                        pass\n",
    "                    \n",
    "                    # 获取工作性质\n",
    "                    job_type = \"-\"\n",
    "                    try:\n",
    "                        job_type = driver.find_element(By.XPATH, '//span[contains(text(), \"工作性质\")]/following-sibling::span').text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 获取工作地点\n",
    "                    work_location = \"-\"\n",
    "                    try:\n",
    "                        work_location = driver.find_element(By.XPATH, '//span[contains(text(), \"工作地点\")]/following-sibling::span').text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 获取岗位描述\n",
    "                    job_description = \"-\"\n",
    "                    try:\n",
    "                        job_description = driver.find_element(By.ID, \"gwms\").text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 获取单位简介\n",
    "                    company_intro = \"-\"\n",
    "                    try:\n",
    "                        # 找到\"单位简介\"下面的span\n",
    "                        span_titles = driver.find_elements(By.CLASS_NAME, \"span-title\")\n",
    "                        for title_elem in span_titles:\n",
    "                            if \"单位简介\" in title_elem.text:\n",
    "                                # 找到对应的div，并获取内容\n",
    "                                intro_div = title_elem.find_element(By.XPATH, \"following-sibling::div[@class='gwmsDiv']\")\n",
    "                                company_intro = intro_div.text.strip()\n",
    "                                break\n",
    "                    except Exception as e:\n",
    "                        # print(f\"获取单位简介失败: {e}\")\n",
    "                        pass\n",
    "                    \n",
    "                    # 获取联系人、电话和邮箱 - 回到原始方法\n",
    "                    contact_name = \"-\"\n",
    "                    contact_phone = \"-\"\n",
    "                    contact_email = \"-\"\n",
    "                    try:\n",
    "                        # 使用直接索引定位联系人、电话和邮箱元素\n",
    "                        contact_div = driver.find_element(By.CLASS_NAME, \"phone\")\n",
    "                        \n",
    "                        try:\n",
    "                            # 获取联系人 - 第一个span元素\n",
    "                            raw_contact = contact_div.find_element(By.XPATH, './/span[1]').text\n",
    "                            contact_name = raw_contact.split(\"：\")[-1].strip()\n",
    "                        except Exception as e:\n",
    "                            # print(f\"获取联系人失败: {e}\")\n",
    "                            pass\n",
    "                        \n",
    "                        try:\n",
    "                            # 获取联系电话 - 第二个span元素\n",
    "                            raw_phone = contact_div.find_element(By.XPATH, './/span[2]').text\n",
    "                            contact_phone = raw_phone.split(\"：\")[-1].strip()\n",
    "                        except Exception as e:\n",
    "                            # print(f\"获取联系电话失败: {e}\")\n",
    "                            pass\n",
    "                        \n",
    "                        try:\n",
    "                            # 获取邮箱 - 第三个span元素\n",
    "                            raw_email = contact_div.find_element(By.XPATH, './/span[3]').text\n",
    "                            contact_email = raw_email.split(\"：\")[-1].strip()\n",
    "                        except Exception as e:\n",
    "                            # print(f\"获取邮箱失败: {e}\")\n",
    "                            pass\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        # print(f\"获取联系信息失败: {e}\")\n",
    "                        pass\n",
    "                \n",
    "                except Exception as e:\n",
    "                    # print(f\"详情页数据提取失败: {e}\")\n",
    "                    company, education, housing, publisher, job_type, work_location = \"-\", \"-\", \"-\", \"-\", \"-\", \"-\"\n",
    "                    job_description, company_intro = \"-\", \"-\"\n",
    "                    contact_name, contact_phone, contact_email = \"-\", \"-\", \"-\"\n",
    "                    actual_salary = job_info[\"salary\"]  # 使用列表页的薪资\n",
    "                    \n",
    "                # 存入数据\n",
    "                data.append([\n",
    "                    job_info[\"job_name\"], \n",
    "                    actual_salary,\n",
    "                    job_info[\"location\"],\n",
    "                    company, \n",
    "                    education,\n",
    "                    housing,\n",
    "                    publisher,\n",
    "                    job_type,\n",
    "                    work_location,\n",
    "                    job_description,\n",
    "                    company_intro,\n",
    "                    contact_name, \n",
    "                    contact_phone,\n",
    "                    contact_email\n",
    "                ])\n",
    "                \n",
    "                record_count += 1  # 增加计数器\n",
    "                \n",
    "                # 每爬取2000条数据保存一次\n",
    "                if record_count % 2000 == 0:\n",
    "                    save_data(data, f\"job_information_part_{record_count // 2000}\")\n",
    "                    print(f\"已完成 {record_count} 条数据爬取\")\n",
    "                    # 保存完数据后清空列表，节省内存\n",
    "                    data = []\n",
    "                \n",
    "                time.sleep(0.1)  # 减少等待时间到0.1秒\n",
    "                \n",
    "            except Exception as e:\n",
    "                # print(f\"详情页处理失败: {e}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        # print(f\"处理页面 {page} 时出错: {e}\")\n",
    "        # 保存现有数据，避免丢失\n",
    "        if data:\n",
    "            save_data(data, f\"job_information_error_recovery_page_{page}\")\n",
    "            data = []  # 保存后清空\n",
    "\n",
    "# 保存剩余的数据（不足2000条的部分）\n",
    "if data:\n",
    "    save_data(data, f\"job_information_final_part\")\n",
    "\n",
    "# 全部数据保存到一个总文件\n",
    "# 读取所有部分文件并合并\n",
    "all_files = [f for f in os.listdir() if f.startswith(\"job_information_part_\") or f.startswith(\"job_information_final_part\") or f.startswith(\"job_information_error_recovery_page_\")]\n",
    "if all_files:\n",
    "    all_data = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file, encoding=\"utf-8-sig\")\n",
    "        all_data.append(df)\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_df.to_csv(\"job_information_combined.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"已合并所有数据，总计 {len(combined_df)} 条记录\")\n",
    "# 关闭浏览器\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5672088-ccb3-4a52-8f5f-2397c4c2068d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
